{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed02617c-1b32-43cb-8f54-2b8cd7de3d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cac7f57-bee7-4411-819d-6eaae262410d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "DATA_ROOT = Path(r\"C:\\Users\\Abdul\\OneDrive\\Desktop\\Varsity\\Deep Learning\\Dataset\")\n",
    "asv2019_root = DATA_ROOT / \"ASVSpoof2019\" / \"LA\" / \"LA\"\n",
    "\n",
    "train_dir = asv2019_root / \"ASVspoof2019_LA_train\"\n",
    "dev_dir   = asv2019_root / \"ASVspoof2019_LA_dev\"\n",
    "eval_dir  = asv2019_root / \"ASVspoof2019_LA_eval\"\n",
    "\n",
    "train_proto = asv2019_root / \"ASVspoof2019_LA_cm_protocols\" / \"ASVspoof2019.LA.cm.train.trn.txt\"\n",
    "dev_proto   = asv2019_root / \"ASVspoof2019_LA_cm_protocols\" / \"ASVspoof2019.LA.cm.dev.trl.txt\"\n",
    "eval_proto  = asv2019_root / \"ASVspoof2019_LA_cm_protocols\" / \"ASVspoof2019.LA.cm.eval.trl.txt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2f6d4cf-fb93-4763-84d7-c8a857cec4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_MAP = {\"bonafide\": 0, \"spoof\": 1}\n",
    "\n",
    "def parse_protocol(proto_path, base_dir):\n",
    "    \"\"\"\n",
    "    Parse ASVspoof2019 LA CM protocol file.\n",
    "\n",
    "    Typical line examples:\n",
    "      LA_0065 LA_T_1000135 - bonafide\n",
    "      LA_0065 LA_T_1000137 A01 spoof\n",
    "\n",
    "    - file_id is the 2nd token (parts[1])\n",
    "    - 'bonafide' or 'spoof' appears somewhere in the line\n",
    "    \"\"\"\n",
    "    entries = []\n",
    "    with open(proto_path, \"r\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line or line.startswith(\"#\"):\n",
    "                continue\n",
    "\n",
    "            parts = line.split()\n",
    "\n",
    "            # 1) file_id in 2nd column\n",
    "            file_id = parts[1]   # e.g., LA_T_1000135\n",
    "\n",
    "            # 2) find label token: bonafide/spoof\n",
    "            label_token = None\n",
    "            for p in parts:\n",
    "                if p in LABEL_MAP:\n",
    "                    label_token = p\n",
    "                    break\n",
    "            if label_token is None:\n",
    "                # no valid label in this line, skip\n",
    "                continue\n",
    "\n",
    "            label = LABEL_MAP[label_token]\n",
    "\n",
    "            # 3) build audio path from file_id\n",
    "            rel_path = file_id + \".flac\"\n",
    "            audio_path = base_dir / \"flac\" / rel_path\n",
    "\n",
    "            entries.append((audio_path, label))\n",
    "\n",
    "    print(f\"Parsed {len(entries)} entries from {proto_path.name}\")\n",
    "    return entries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79f5513b-126b-4a34-8030-2eaae91c50ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import librosa\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def pad_or_truncate_audio(y, target_len=64000):\n",
    "    if len(y) < target_len:\n",
    "        pad_len = target_len - len(y)\n",
    "        y = np.pad(y, (0, pad_len), mode=\"constant\")\n",
    "    else:\n",
    "        y = y[:target_len]\n",
    "    return y\n",
    "\n",
    "class ASVspoof2019LADataset(Dataset):\n",
    "    def __init__(self, split=\"train\"):\n",
    "        if split == \"train\":\n",
    "            self.base_dir = train_dir\n",
    "            self.proto_path = train_proto\n",
    "        elif split == \"dev\":\n",
    "            self.base_dir = dev_dir\n",
    "            self.proto_path = dev_proto\n",
    "        else:\n",
    "            self.base_dir = eval_dir\n",
    "            self.proto_path = eval_proto\n",
    "\n",
    "        self.entries = parse_protocol(self.proto_path, self.base_dir)\n",
    "        print(f\"{split} split: {len(self.entries)} files\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.entries)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        audio_path, label = self.entries[idx]\n",
    "        y, sr = librosa.load(audio_path, sr=16000)\n",
    "        y = pad_or_truncate_audio(y, target_len=64000)\n",
    "        y = torch.tensor(y, dtype=torch.float32).unsqueeze(0)  # [1, T]\n",
    "        return y, torch.tensor(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "977d90d2-7ce3-4bfc-93f3-18b744a04a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed 71237 entries from ASVspoof2019.LA.cm.eval.trl.txt\n",
      "eval split: 71237 files\n"
     ]
    }
   ],
   "source": [
    "batch_size = 4\n",
    "\n",
    "eval_dataset = ASVspoof2019LADataset(split=\"eval\")\n",
    "eval_loader = DataLoader(eval_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c4084f9-57fb-4e27-95fe-8791565b1834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed 25380 entries from ASVspoof2019.LA.cm.train.trn.txt\n",
      "train split: 25380 files\n",
      "Parsed 24844 entries from ASVspoof2019.LA.cm.dev.trl.txt\n",
      "dev split: 24844 files\n"
     ]
    }
   ],
   "source": [
    "train_dataset = ASVspoof2019LADataset(split=\"train\")\n",
    "dev_dataset   = ASVspoof2019LADataset(split=\"dev\")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "dev_loader   = DataLoader(dev_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9af4305-d1ac-4471-b503-6667dee759ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ResBlockRawNet2(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size=3,\n",
    "                               stride=stride, padding=1, bias=False)\n",
    "        self.bn1   = nn.BatchNorm1d(out_channels)\n",
    "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn2   = nn.BatchNorm1d(out_channels)\n",
    "\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv1d(in_channels, out_channels, kernel_size=1,\n",
    "                          stride=stride, bias=False),\n",
    "                nn.BatchNorm1d(out_channels)\n",
    "            )\n",
    "        else:\n",
    "            self.shortcut = nn.Identity()\n",
    "\n",
    "        self.act = nn.LeakyReLU(0.3, inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.act(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        shortcut = self.shortcut(x)\n",
    "\n",
    "        out = out + shortcut\n",
    "        out = self.act(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class RawNet2(nn.Module):\n",
    "    \"\"\"\n",
    "    RawNet2-style architecture (simplified) for ASVspoof2019 LA.\n",
    "    Input: [B, 1, T] raw waveform (e.g. T=64000)\n",
    "    \"\"\"\n",
    "    def __init__(self, n_classes=2):\n",
    "        super().__init__()\n",
    "        self.act = nn.LeakyReLU(0.3, inplace=True)\n",
    "\n",
    "        self.conv_in = nn.Conv1d(1, 64, kernel_size=3, stride=3, padding=1, bias=False)\n",
    "        self.bn_in   = nn.BatchNorm1d(64)\n",
    "\n",
    "        self.block1 = ResBlockRawNet2(64, 64, stride=1)   # T/3\n",
    "        self.block2 = ResBlockRawNet2(64, 128, stride=3)  # ~T/9\n",
    "        self.block3 = ResBlockRawNet2(128, 128, stride=3) # ~T/27\n",
    "        self.block4 = ResBlockRawNet2(128, 256, stride=3) # ~T/81\n",
    "        self.block5 = ResBlockRawNet2(256, 256, stride=1)\n",
    "\n",
    "        self.gru = nn.GRU(\n",
    "            input_size=256,\n",
    "            hidden_size=256,\n",
    "            num_layers=2,\n",
    "            batch_first=True,\n",
    "            bidirectional=False,\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Linear(256, n_classes)\n",
    "\n",
    "    def forward(self, x, return_embedding: bool = False):\n",
    "        \"\"\"\n",
    "        x: [B, 1, T]\n",
    "        If return_embedding=True, returns (logits, h_last)\n",
    "        Else returns logits only.\n",
    "        \"\"\"\n",
    "        x = self.conv_in(x)\n",
    "        x = self.bn_in(x)\n",
    "        x = self.act(x)\n",
    "\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = self.block4(x)\n",
    "        x = self.block5(x)\n",
    "\n",
    "        x = x.transpose(1, 2)   # [B, T_seq, 256]\n",
    "\n",
    "        out, h_n = self.gru(x)  # h_n: [num_layers, B, 256]\n",
    "        h_last = h_n[-1]        # [B, 256] â†’ this is our embedding\n",
    "\n",
    "        logits = self.fc(h_last)  # [B, n_classes]\n",
    "\n",
    "        if return_embedding:\n",
    "            return logits, h_last\n",
    "        else:\n",
    "            return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45b34331-c5d1-44f6-8293-fb887e7aeb44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdul\\AppData\\Local\\Temp\\ipykernel_20536\\2869392584.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(\"rawnet2_best.pth\", map_location=device)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RawNet2(\n",
       "  (act): LeakyReLU(negative_slope=0.3, inplace=True)\n",
       "  (conv_in): Conv1d(1, 64, kernel_size=(3,), stride=(3,), padding=(1,), bias=False)\n",
       "  (bn_in): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (block1): ResBlockRawNet2(\n",
       "    (conv1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "    (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "    (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (shortcut): Identity()\n",
       "    (act): LeakyReLU(negative_slope=0.3, inplace=True)\n",
       "  )\n",
       "  (block2): ResBlockRawNet2(\n",
       "    (conv1): Conv1d(64, 128, kernel_size=(3,), stride=(3,), padding=(1,), bias=False)\n",
       "    (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "    (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (shortcut): Sequential(\n",
       "      (0): Conv1d(64, 128, kernel_size=(1,), stride=(3,), bias=False)\n",
       "      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (act): LeakyReLU(negative_slope=0.3, inplace=True)\n",
       "  )\n",
       "  (block3): ResBlockRawNet2(\n",
       "    (conv1): Conv1d(128, 128, kernel_size=(3,), stride=(3,), padding=(1,), bias=False)\n",
       "    (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "    (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (shortcut): Sequential(\n",
       "      (0): Conv1d(128, 128, kernel_size=(1,), stride=(3,), bias=False)\n",
       "      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (act): LeakyReLU(negative_slope=0.3, inplace=True)\n",
       "  )\n",
       "  (block4): ResBlockRawNet2(\n",
       "    (conv1): Conv1d(128, 256, kernel_size=(3,), stride=(3,), padding=(1,), bias=False)\n",
       "    (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "    (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (shortcut): Sequential(\n",
       "      (0): Conv1d(128, 256, kernel_size=(1,), stride=(3,), bias=False)\n",
       "      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (act): LeakyReLU(negative_slope=0.3, inplace=True)\n",
       "  )\n",
       "  (block5): ResBlockRawNet2(\n",
       "    (conv1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "    (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "    (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (shortcut): Identity()\n",
       "    (act): LeakyReLU(negative_slope=0.3, inplace=True)\n",
       "  )\n",
       "  (gru): GRU(256, 256, num_layers=2, batch_first=True)\n",
       "  (fc): Linear(in_features=256, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "model = RawNet2(n_classes=2).to(device)\n",
    "state = torch.load(\"rawnet2_best.pth\", map_location=device)\n",
    "model.load_state_dict(state)\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0fdd23e3-1b46-4b26-b2e5-5f463f01f40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def extract_embeddings(model, loader, device):\n",
    "    model.eval()\n",
    "    all_embs = []\n",
    "    all_labels = []\n",
    "    all_scores = []\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for audio_batch, labels in loader:\n",
    "            audio_batch = audio_batch.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            logits, emb = model(audio_batch, return_embedding=True)  # [B,2], [B,256]\n",
    "            probs = torch.softmax(logits, dim=1)[:, 1]               # spoof prob\n",
    "\n",
    "            all_embs.append(emb.cpu().numpy())       # [B, 256]\n",
    "            all_labels.append(labels.cpu().numpy())  # [B]\n",
    "            all_scores.append(probs.cpu().numpy())   # [B]\n",
    "\n",
    "    embeddings = np.concatenate(all_embs, axis=0)\n",
    "    labels = np.concatenate(all_labels, axis=0)\n",
    "    scores = np.concatenate(all_scores, axis=0)\n",
    "\n",
    "    print(\"Embeddings shape:\", embeddings.shape)\n",
    "    print(\"Labels shape:\", labels.shape)\n",
    "    print(\"Scores shape:\", scores.shape)\n",
    "\n",
    "    return embeddings, labels, scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53543b8d-1eb1-4142-8641-7caf70b7b65d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings shape: (71237, 256)\n",
      "Labels shape: (71237,)\n",
      "Scores shape: (71237,)\n",
      "Saved eval embeddings to rawnet2_eval_embeddings.npz\n"
     ]
    }
   ],
   "source": [
    "emb_eval, labels_eval, scores_eval = extract_embeddings(model, eval_loader, device)\n",
    "\n",
    "np.savez(\n",
    "    \"rawnet2_eval_embeddings.npz\",\n",
    "    embeddings=emb_eval,\n",
    "    labels=labels_eval,\n",
    "    scores=scores_eval,\n",
    ")\n",
    "print(\"Saved eval embeddings to rawnet2_eval_embeddings.npz\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5da1159f-405e-4ff9-8bee-1c1907c8927b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'eval_scores' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Threshold at 0.5\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m pred \u001b[38;5;241m=\u001b[39m (\u001b[43meval_scores\u001b[49m \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Confusion Matrix\u001b[39;00m\n\u001b[0;32m      9\u001b[0m cm \u001b[38;5;241m=\u001b[39m confusion_matrix(eval_labels, pred)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'eval_scores' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Threshold at 0.5\n",
    "pred = (eval_scores >= 0.5).astype(int)\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(eval_labels, pred)\n",
    "\n",
    "print(\"Confusion Matrix (Raw Counts):\")\n",
    "print(cm)\n",
    "\n",
    "# Pretty Plot\n",
    "disp = ConfusionMatrixDisplay(cm, display_labels=[\"Bonafide (0)\", \"Spoof (1)\"])\n",
    "fig, ax = plt.subplots(figsize=(4,4))\n",
    "disp.plot(ax=ax, values_format='d', colorbar=False)\n",
    "plt.title(\"RawNet2 Confusion Matrix (Eval)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a6d16c58-5e6c-45f3-80fd-8bd76e3eb68d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m cm_norm \u001b[38;5;241m=\u001b[39m \u001b[43mcm\u001b[49m\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m/\u001b[39m cm\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)[:, np\u001b[38;5;241m.\u001b[39mnewaxis]\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mNormalized Confusion Matrix:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(cm_norm)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cm' is not defined"
     ]
    }
   ],
   "source": [
    "cm_norm = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "print(\"\\nNormalized Confusion Matrix:\")\n",
    "print(cm_norm)\n",
    "\n",
    "# Plot\n",
    "disp_norm = ConfusionMatrixDisplay(confusion_matrix=cm_norm,\n",
    "                                   display_labels=[\"Bonafide (0)\", \"Spoof (1)\"])\n",
    "fig, ax = plt.subplots(figsize=(4,4))\n",
    "disp_norm.plot(ax=ax, values_format='.2f', colorbar=True)\n",
    "plt.title(\"RawNet2 Normalized Confusion Matrix (Eval)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2904862d-1b27-4947-acbc-5f0c5996e545",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'eval_labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m roc_curve\n\u001b[1;32m----> 3\u001b[0m fpr, tpr, thresholds \u001b[38;5;241m=\u001b[39m roc_curve(\u001b[43meval_labels\u001b[49m, eval_scores)\n\u001b[0;32m      4\u001b[0m fnr \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m tpr\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Find EER\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'eval_labels' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(eval_labels, eval_scores)\n",
    "fnr = 1 - tpr\n",
    "\n",
    "# Find EER\n",
    "eer_idx = np.nanargmin(np.abs(fnr - fpr))\n",
    "eer = fpr[eer_idx]\n",
    "eer_fpr = fpr[eer_idx]\n",
    "eer_tpr = tpr[eer_idx]\n",
    "\n",
    "print(\"EER:\", eer)\n",
    "print(\"EER threshold:\", thresholds[eer_idx])\n",
    "\n",
    "# Plot ROC\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.plot(fpr, tpr, label=\"ROC Curve\")\n",
    "plt.plot([0,1], [0,1], 'k--', label=\"Random\")\n",
    "plt.scatter(eer_fpr, eer_tpr, color=\"red\", label=f\"EER = {eer:.3f}\")\n",
    "plt.title(\"RawNet2 ROC Curve (Eval)\")\n",
    "plt.xlabel(\"False Positive Rate (FPR)\")\n",
    "plt.ylabel(\"True Positive Rate (TPR)\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b1b24681-8aa4-4d04-a420-f6c250371599",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m TN, FP, FN, TP \u001b[38;5;241m=\u001b[39m \u001b[43mcm\u001b[49m\u001b[38;5;241m.\u001b[39mravel()\n\u001b[0;32m      3\u001b[0m summary \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTN (Correct Bonafide)\u001b[39m\u001b[38;5;124m\"\u001b[39m: TN,\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFP (Bonafide classified as Spoof)\u001b[39m\u001b[38;5;124m\"\u001b[39m: FP,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEER\u001b[39m\u001b[38;5;124m\"\u001b[39m: eer\n\u001b[0;32m     12\u001b[0m }\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m=== PERFORMANCE SUMMARY MATRIX ===\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cm' is not defined"
     ]
    }
   ],
   "source": [
    "TN, FP, FN, TP = cm.ravel()\n",
    "\n",
    "summary = {\n",
    "    \"TN (Correct Bonafide)\": TN,\n",
    "    \"FP (Bonafide classified as Spoof)\": FP,\n",
    "    \"FN (Spoof classified as Bonafide)\": FN,\n",
    "    \"TP (Correct Spoof)\": TP,\n",
    "    \"Accuracy\": (TP + TN) / (TP + TN + FP + FN),\n",
    "    \"Bonafide Detection Rate (TNR)\": TN / (TN + FP),\n",
    "    \"Spoof Detection Rate (TPR)\": TP / (TP + FN),\n",
    "    \"EER\": eer\n",
    "}\n",
    "\n",
    "print(\"\\n=== PERFORMANCE SUMMARY MATRIX ===\")\n",
    "for k, v in summary.items():\n",
    "    print(f\"{k}: {v}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1f3cd7-2044-4a31-9395-996e6cade46a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
